{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manabil/Tensorflow-Advanced-Techniques-Specialization/blob/main/Custom%20Models%2C%20Layers%2C%20Loss%20Functions%20with%20Tensorflow/Week%202/C1_W2_Lab_2_huber_object_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPS9Kj7A1Y1q"
      },
      "source": [
        "# Ungraded Lab: Huber Loss hyperparameter and class\n",
        "\n",
        "In this lab, we'll extend our previous Huber loss function and show how you can include hyperparameters in defining loss functions. We'll also look at how to implement a custom loss as an object by inheriting the [Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss) class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mssgAsua1Y1z"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0p84I7yFHRT2",
        "outputId": "de6fc25f-3b3b-4000-d65f-ad7e112b90ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from typing import Callable\n",
        "from tensorflow.keras.losses import Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsUHQKoq1Y1-"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "As before, this model will be trained on the `xs` and `ys` below where the relationship is $y = 2x-1$. Thus, later, when we test for `x=10`, whichever version of the model gets the closest answer to `19` will be deemed more accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "0pajvrhrInPa"
      },
      "outputs": [],
      "source": [
        "# inputs\n",
        "xs: np.ndarray = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
        "\n",
        "# labels\n",
        "ys: np.ndarray = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELOmXX3X1Y2I"
      },
      "source": [
        "## Custom loss with hyperparameter\n",
        "\n",
        "The `loss` argument in `model.compile()` only accepts functions that accepts two parameters: the ground truth (`y_true`) and the model predictions (`y_pred`). If we want to include a hyperparameter that we can tune, then we can define a wrapper function that accepts this hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FvRZpxk2tGn6"
      },
      "outputs": [],
      "source": [
        "# wrapper function that accepts the hyperparameter\n",
        "def my_huber_loss_with_threshold(threshold: float) -> Callable[[tf.Tensor,\n",
        "                                                                tf.Tensor], tf.Tensor]:\n",
        "\n",
        "    # function that accepts the ground truth and predictions\n",
        "    def my_huber_loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
        "        error: tf.Tensor = tf.subtract(x=y_true, y=y_pred)\n",
        "        is_small_error: tf.Tensor = tf.abs(error) <= threshold\n",
        "        small_error_loss: tf.Tensor = tf.square(error) / 2\n",
        "        big_error_loss: tf.Tensor = threshold * (tf.abs(error) - (0.5*threshold))\n",
        "\n",
        "        return tf.where(is_small_error, small_error_loss, big_error_loss)\n",
        "\n",
        "    # return the inner function tuned by the hyperparameter\n",
        "    return my_huber_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu4RDp8f1Y2P"
      },
      "source": [
        "We can now specify the `loss` as the wrapper function above. Notice that we can now set the `threshold` value. Try varying this value and see the results you get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7rgmb5qH5QX",
        "outputId": "820feade-aaf7-4c49-ec7d-65b17c58a37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cb381a49510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n",
            "[[18.487938]]\n"
          ]
        }
      ],
      "source": [
        "model: tf.keras.Sequential = tf.keras.Sequential(\n",
        "    [tf.keras.layers.Dense(units=1, input_shape=[1])]\n",
        ")\n",
        "model.compile(\n",
        "    optimizer='sgd', loss=my_huber_loss_with_threshold(threshold=1.2)\n",
        ")\n",
        "model.fit(xs, ys, epochs=500,verbose=0)\n",
        "print(model.predict([10.0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZhLiIhB1Y2c"
      },
      "source": [
        "## Implement Custom Loss as a Class\n",
        "\n",
        "We can also implement our custom loss as a class. It inherits from the Keras Loss class and the syntax and required methods are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "iderl2m0saTa"
      },
      "outputs": [],
      "source": [
        "class MyHuberLoss(Loss):\n",
        "    \"\"\"Custom Huber Loss with changeable threshold\"\"\"\n",
        "\n",
        "    # initialize instance attributes\n",
        "    def __init__(self, threshold: float=1):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    # compute loss\n",
        "    def call(self, y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
        "        error: tf.Tensor = tf.subtract(x=y_true, y=y_pred)\n",
        "        is_small_error: tf.Tensor = tf.abs(error) <= self.threshold\n",
        "        small_error_loss: tf.Tensor = tf.square(error) / 2\n",
        "        big_error_loss: tf.Tensor = (self.threshold\n",
        "                                     * (tf.abs(error)\n",
        "                                     - (0.5*self.threshold)))\n",
        "        return tf.where(is_small_error, small_error_loss, big_error_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQu-Xs_j1Y2l"
      },
      "source": [
        "You can specify the loss by instantiating an object from your custom loss class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwKWfSmDIayP",
        "outputId": "1c0f404f-a7c5-4d38-cf13-02d566e04a40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7cb381a4add0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 61ms/step\n",
            "[[18.604467]]\n"
          ]
        }
      ],
      "source": [
        "model: tf.keras.Sequential = tf.keras.Sequential(\n",
        "    [tf.keras.layers.Dense(units=1, input_shape=[1])]\n",
        ")\n",
        "model.compile(optimizer='sgd', loss=MyHuberLoss(threshold=1.02))\n",
        "model.fit(xs, ys, epochs=500, verbose=0)\n",
        "print(model.predict([10.0]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}